"""
Script ƒë·ªÉ predict v√† l∆∞u th√¥ng tin bounding box v√† label cho t·∫≠p test
"""

import os
import json
import cv2
import torch
from ultralytics import YOLO
from datetime import datetime
import pandas as pd
from pathlib import Path

# Mapping labels
label2id = {
    "abdominal_wall_cavity": 2,
    "cystic_duct": 5,
    "cystic_plate": 0,
    "gallbladder": 1,
    "gut": 6,
    "liver": 4,
    "omentum": 3,
    "bipolar": 7,
    "clipper": 8,
    "grasper": 9,
    "hook": 10,
    "irrigator": 11,
    "scissors": 12,
    "specimenbag": 13,
}

id2label = {v: k for k, v in label2id.items()}

class YOLOPredictor:
    def __init__(self, model_path, confidence_threshold=0.25):
        """
        Kh·ªüi t·∫°o YOLO predictor
        
        Args:
            model_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn model weights
            confidence_threshold (float): Ng∆∞·ª°ng confidence cho detection
        """
        self.model = YOLO(model_path)
        self.conf_threshold = confidence_threshold
        self.results_data = []
        
    def predict_single_image(self, image_path):
        """
        Predict m·ªôt ·∫£nh duy nh·∫•t
        
        Args:
            image_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
            
        Returns:
            dict: Th√¥ng tin prediction cho ·∫£nh
        """
        # Th·ª±c hi·ªán prediction
        results = self.model.predict(
            source=image_path,
            conf=self.conf_threshold,
            imgsz=(480, 860),
            save=False,  # Kh√¥ng l∆∞u ·∫£nh prediction
            verbose=False
        )
        
        result = results[0]
        image_name = os.path.basename(image_path)
        
        # L·∫•y th√¥ng tin ·∫£nh v·ªõi x·ª≠ l√Ω l·ªói
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Cannot read image: {image_path}")
        img_height, img_width = img.shape[:2]
        
        predictions = []
        
        if result.boxes is not None:
            boxes = result.boxes.xyxy.cpu().numpy()  # x1, y1, x2, y2
            scores = result.boxes.conf.cpu().numpy()
            classes = result.boxes.cls.cpu().numpy().astype(int)
            
            for i, (box, score, cls) in enumerate(zip(boxes, scores, classes)):
                x1, y1, x2, y2 = box
                width = x2 - x1
                height = y2 - y1
                
                # Normalize coordinates (0-1)
                x1_norm = x1 / img_width
                y1_norm = y1 / img_height
                x2_norm = x2 / img_width
                y2_norm = y2 / img_height
                width_norm = width / img_width
                height_norm = height / img_height
                
                prediction_info = {
                    'image_name': image_name,
                    'detection_id': i,
                    'class_id': int(cls),
                    'class_name': id2label.get(int(cls), f'unknown_{cls}'),
                    'confidence': float(score),
                    'bbox_x1': float(x1),
                    'bbox_y1': float(y1),
                    'bbox_x2': float(x2),
                    'bbox_y2': float(y2),
                    'bbox_width': float(width),
                    'bbox_height': float(height),
                    'bbox_x1_norm': float(x1_norm),
                    'bbox_y1_norm': float(y1_norm),
                    'bbox_x2_norm': float(x2_norm),
                    'bbox_y2_norm': float(y2_norm),
                    'bbox_width_norm': float(width_norm),
                    'bbox_height_norm': float(height_norm),
                    'image_width': img_width,
                    'image_height': img_height
                }
                predictions.append(prediction_info)
        
        return {
            'image_name': image_name,
            'image_path': image_path,
            'image_width': img_width,
            'image_height': img_height,
            'num_detections': len(predictions),
            'predictions': predictions
        }
    
    def predict_test_set(self, test_images_dir, output_dir='prediction_results'):
        """
        Predict to√†n b·ªô t·∫≠p test v√† l∆∞u k·∫øt qu·∫£
        
        Args:
            test_images_dir (str): Th∆∞ m·ª•c ch·ª©a ·∫£nh test
            output_dir (str): Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        """
        print(f"üîç Starting prediction on test set...")
        print(f"üìÇ Test images directory: {test_images_dir}")
        print(f"üíæ Output directory: {output_dir}")
        
        # T·∫°o th∆∞ m·ª•c output
        os.makedirs(output_dir, exist_ok=True)
        
        # L·∫•y danh s√°ch t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c test
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(Path(test_images_dir).glob(f'*{ext}'))
        
        # Lo·∫°i b·ªè duplicates n·∫øu c√≥
        image_files = list(set(image_files))
        
        if not image_files:
            print("‚ùå No images found in test directory!")
            return
        
        print(f"üñº Found {len(image_files)} images to process")
        
        all_predictions = []
        all_detections = []
        
        # Process t·ª´ng ·∫£nh
        successful_count = 0
        error_count = 0
        
        for i, image_path in enumerate(image_files):
            if i % 100 == 0 or i == len(image_files) - 1:  # Progress update m·ªói 100 ·∫£nh ho·∫∑c ·∫£nh cu·ªëi
                progress = (i + 1) / len(image_files) * 100
                print(f"Progress: {i+1}/{len(image_files)} ({progress:.1f}%) - Processing: {image_path.name}")
            elif i % 10 == 0:  # Simple counter m·ªói 10 ·∫£nh
                print(f"Processing {i+1}/{len(image_files)}: {image_path.name}")
            
            try:
                # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i v√† c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c kh√¥ng
                if not os.path.exists(str(image_path)):
                    print(f"‚ö†Ô∏è File not found: {image_path.name}")
                    error_count += 1
                    continue
                    
                # Th·ª≠ ƒë·ªçc ·∫£nh tr∆∞·ªõc khi predict
                test_img = cv2.imread(str(image_path))
                if test_img is None:
                    print(f"‚ö†Ô∏è Cannot read image: {image_path.name}")
                    error_count += 1
                    continue
                
                result = self.predict_single_image(str(image_path))
                all_predictions.append(result)
                
                # Th√™m c√°c detection v√†o danh s√°ch chung
                for pred in result['predictions']:
                    all_detections.append(pred)
                
                successful_count += 1
                    
            except Exception as e:
                print(f"‚ùå Error processing {image_path.name}: {str(e)}")
                error_count += 1
                continue
        
        # L∆∞u k·∫øt qu·∫£
        self._save_results(all_predictions, all_detections, output_dir)
        
        print(f"‚úÖ Prediction completed!")
        print(f"üìä Total images found: {len(image_files)}")
        print(f"üìä Successfully processed: {successful_count}")
        print(f"üìä Errors encountered: {error_count}")
        print(f"üìä Total detections: {len(all_detections)}")
        
        return all_predictions, all_detections
    
    def _save_results(self, all_predictions, all_detections, output_dir):
        """
        L∆∞u k·∫øt qu·∫£ prediction ra c√°c file kh√°c nhau
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. L∆∞u t·ªïng quan k·∫øt qu·∫£ m·ªói ·∫£nh (JSON)
        summary_file = os.path.join(output_dir, f'prediction_summary_{timestamp}.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(all_predictions, f, indent=2, ensure_ascii=False)
        print(f"üíæ Saved prediction summary to: {summary_file}")
        
        # 2. L∆∞u t·∫•t c·∫£ detections (CSV)
        if all_detections:
            df_detections = pd.DataFrame(all_detections)
            csv_file = os.path.join(output_dir, f'all_detections_{timestamp}.csv')
            df_detections.to_csv(csv_file, index=False)
            print(f"üíæ Saved all detections to: {csv_file}")
            
            # 3. L∆∞u th·ªëng k√™ theo class
            class_stats = df_detections.groupby('class_name').agg({
                'confidence': ['count', 'mean', 'std', 'min', 'max'],
                'bbox_width_norm': 'mean',
                'bbox_height_norm': 'mean'
            }).round(4)
            
            stats_file = os.path.join(output_dir, f'class_statistics_{timestamp}.csv')
            class_stats.to_csv(stats_file)
            print(f"üíæ Saved class statistics to: {stats_file}")
        
        # 4. L∆∞u file YOLO format cho m·ªói ·∫£nh (ƒë·ªÉ c√≥ th·ªÉ so s√°nh v·ªõi ground truth)
        yolo_dir = os.path.join(output_dir, 'yolo_predictions')
        os.makedirs(yolo_dir, exist_ok=True)
        
        for pred_result in all_predictions:
            if pred_result['predictions']:
                image_name = pred_result['image_name']
                txt_name = os.path.splitext(image_name)[0] + '.txt'
                txt_path = os.path.join(yolo_dir, txt_name)
                
                with open(txt_path, 'w') as f:
                    for pred in pred_result['predictions']:
                        # Convert to YOLO format: class_id center_x center_y width height
                        center_x = (pred['bbox_x1_norm'] + pred['bbox_x2_norm']) / 2
                        center_y = (pred['bbox_y1_norm'] + pred['bbox_y2_norm']) / 2
                        width = pred['bbox_width_norm']
                        height = pred['bbox_height_norm']
                        
                        f.write(f"{pred['class_id']} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n")
        
        print(f"üíæ Saved YOLO format predictions to: {yolo_dir}")

def main():
    """
    Main function ƒë·ªÉ ch·∫°y prediction
    """
    # C·∫•u h√¨nh paths - C·∫¨P NH·∫¨T THEO D·ª∞ √ÅN C·ª¶A B·∫†N
    model_path = r"D:\\KLTN\\gnn-surgical-understanding\\detection_model\\runs\\detect\\train3\\weights\\best.pt"  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn model weights
    test_images_dir = r"D:\\KLTN\\gnn-surgical-understanding\\detection_model\\dataset\\images\\test"  # Th∆∞ m·ª•c ch·ª©a ·∫£nh test
    output_dir = r"D:\\KLTN\\gnn-surgical-understanding\\detection_model\\prediction_results"  # Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    confidence_threshold = 0.25  # Ng∆∞·ª°ng confidence
    
    # Ki·ªÉm tra file model c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(model_path):
        print(f"‚ùå Model file not found: {model_path}")
        print("Please update the model_path variable to point to your trained model")
        return
    
    # Ki·ªÉm tra th∆∞ m·ª•c test c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(test_images_dir):
        print(f"‚ùå Test images directory not found: {test_images_dir}")
        print("Please update the test_images_dir variable to point to your test images")
        return
    
    print("üöÄ Starting YOLO Prediction and Results Saving...")
    print(f"üéØ Model: {model_path}")
    print(f"üìÅ Test images: {test_images_dir}")
    print(f"üéö Confidence threshold: {confidence_threshold}")
    
    # Kh·ªüi t·∫°o predictor
    predictor = YOLOPredictor(model_path, confidence_threshold)
    
    # Th·ª±c hi·ªán prediction
    predictions, detections = predictor.predict_test_set(test_images_dir, output_dir)
    
    print("\nüìà PREDICTION SUMMARY:")
    print(f"Total images: {len(predictions)}")
    print(f"Total detections: {len(detections)}")
    
    if detections:
        df = pd.DataFrame(detections)
        print(f"Average confidence: {df['confidence'].mean():.3f}")
        print(f"Classes detected: {df['class_name'].nunique()}")
        print("\nClass distribution:")
        print(df['class_name'].value_counts())

if __name__ == "__main__":
    main()